server:
  ingress:
    enabled: true
    annotations:
      ingress.kubernetes.io/ssl-redirect: "false"
      nginx.ingress.kubernetes.io/ssl-redirect: "false"
  resources:
    limits:
      cpu: 100m
      memory: 1000Mi
    requests:
      cpu: 10m
      memory: 500Mi
alertmanager:
  ingress:
    enabled: true
    annotations:
      ingress.kubernetes.io/ssl-redirect: "false"
      nginx.ingress.kubernetes.io/ssl-redirect: "false"
  resources:
    limits:
      cpu: 10m
      memory: 20Mi
    requests:
      cpu: 5m
      memory: 10Mi
kubeStateMetrics:
  resources:
    limits:
      cpu: 10m
      memory: 50Mi
    requests:
      cpu: 5m
      memory: 25Mi
nodeExporter:
  resources:
    limits:
      cpu: 10m
      memory: 20Mi
    requests:
      cpu: 5m
      memory: 10Mi
pushgateway:
  resources:
    limits:
      cpu: 10m
      memory: 20Mi
    requests:
      cpu: 5m
      memory: 10Mi
serverFiles:
  alerts:
    groups:
    - name: latency
      rules:
      - alert: AppTooSlow
        expr: sum(rate(nginx_ingress_controller_request_duration_seconds_bucket{le="0.25"}[5m])) by (ingress) / sum(rate(nginx_ingress_controller_request_duration_seconds_count[5m])) by (ingress) < 0.95
        labels:
          severity: notify
        annotations:
          identifier: '{{ $labels.ingress }}'
          summary: "Application is too slow (ingress {{ $labels.ingress }})"
          description: "More then 5% of requests are slower than 0.25s Labels: {{ $labels }}"
      - alert: TooManyRequests
        expr: sum(rate(nginx_ingress_controller_requests[5m])) by (ingress) / sum(label_join(kube_deployment_status_replicas, "ingress", ",", "deployment")) by (ingress) > 1
        labels:
          severity: notify
        annotations:
          identifier: '{{ $labels.ingress }}'
          summary: Too many requests
          description: "There is more than average of 1 requests per second per replica for at least one application {{ $labels }}"
    - name: nodes
      rules:
      - alert: TooManyNodes
        expr: count(kube_node_info) > 3
        for: 1m
        labels:
          severity: notify
        annotations:
          identifier: TMN
          summary: Cluster increased
          description: "The number of the nodes in the cluster increased"
      - alert: TooFewNodes
        expr: count(kube_node_info) < 1
        for: 1m
        labels:
          severity: notify
        annotations:
          identifier: TFN
          summary: Cluster decreased
          description: "The number of the nodes in the cluster decreased"
      - alert: NotEnoughCPU
        expr: sum(rate(node_cpu_seconds_total{mode!="idle", mode!="iowait", mode!~"^(?:guest.*)$"}[5m])) / count(node_cpu_seconds_total{mode="system"}) > 0.9
        for: 30m
        labels:
          severity: notify
        annotations:
          summary: There's not enough CPU
          description: CPU usage of the cluster is above 90%
      - alert: TooMuchCPURequested
        expr: sum(kube_pod_container_resource_requests_cpu_cores) / sum(kube_node_status_allocatable_cpu_cores) > 0.9
        for: 30m
        labels:
          severity: notify
        annotations:
          summary: There's not enough allocatable CPU
          description: More than 90% of allocatable CPU is requested
      - alert: NotEnoughMemory
        expr: 1 - sum(node_memory_MemAvailable_bytes) / sum(node_memory_MemTotal_bytes) > 0.9
        for: 30m
        labels:
          severity: notify
        annotations:
          summary: There's not enough memory
          description: Memory usage of the cluster is above 90%
      - alert: TooMuchMemoryRequested
        expr: sum(kube_pod_container_resource_requests_memory_bytes) / sum(kube_node_status_allocatable_memory_bytes) > 0.9
        for: 30m
        labels:
          severity: notify
        annotations:
          summary: There's not enough allocatable memory
          description: More than 90% of allocatable memory is requested
      - alert: TooMuchCPUAndMemory
        expr: (sum(rate(node_cpu_seconds_total{mode!="idle", mode!="iowait", mode!~"^(?:guest.*)$"}[5m])) by (instance) / count(node_cpu_seconds_total{mode="system"}) by (instance)) < 0.5 and (1 - sum(node_memory_MemAvailable_bytes) by (instance) / sum(node_memory_MemTotal_bytes) by (instance)) < 0.5
        for: 30m
        labels:
          severity: notify
        annotations:
          summary: Too much unused CPU and memory
          description: Less than 50% of CPU and 50% of memory is used on at least one node
    - name: errors
      rules:
      - alert: TooManyErrors
        expr: sum(rate(nginx_ingress_controller_requests{status=~"5.."}[5m])) by (ingress) / sum(rate(nginx_ingress_controller_requests[5m])) by (ingress) > 0.025
        labels:
          severity: error
        annotations:
          summary: Too many errors
          description: At least one application produced more then 5% of error responses
alertmanagerFiles:
  alertmanager.yml:
    global: {}
    route:
      group_wait: 10s
      group_interval: 5m
      receiver: slack
      repeat_interval: 3h
      routes:
      - receiver: slack
        repeat_interval: 5d
        match:
          severity: notify
          frequency: low
    receivers:
    - name: slack
      slack_configs:
      - api_url: "https://hooks.slack.com/services/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"
        send_resolved: true
        channel: '#testing'
        title: '{{ template "slack.mon.title" . }}'
        text: '{{ template "slack.mon.text" . }}'
        title_link: http://mon.34.246.236.205.nip.io/alerts
    templates:
    - /etc/config/mon.tmpl

  mon.tmpl: |
    {{ define "__single_message_title" }}{{ range .Alerts.Firing }}{{ .Labels.alertname }} @ {{ .Annotations.summary }}{{ end }}{{ range .Alerts.Resolved }}{{ .Labels.alertname }} @ {{ .Annotations.summary }}{{ end }}{{ end }}
    {{ define "slack.mon.title" }}[{{ .Status | toUpper }}{{ if eq .Status "firing" }}:{{ .Alerts.Firing | len }}{{ end }}] {{ if or (and (eq (len .Alerts.Firing) 1) (eq (len .Alerts.Resolved) 0)) (and (eq (len .Alerts.Firing) 0) (eq (len .Alerts.Resolved) 1)) }}{{ template "__single_message_title" . }}{{ end }}{{ end }}
    {{ define "slack.mon.text" }}
       {{ if or (and (eq (len .Alerts.Firing) 1) (eq (len .Alerts.Resolved) 0)) (and (eq (len .Alerts.Firing) 0) (eq (len .Alerts.Resolved) 1)) }}
          {{ range .Alerts.Firing }}{{ .Annotations.description }}{{ end }}
          {{ range .Alerts.Resolved }}{{ .Annotations.description }}{{ end }}
       {{ else }}
          {{ if gt (len .Alerts.Firing) 0 }}
          *Alerts Firing:*
             {{ range .Alerts.Firing }}- {{ .Annotations.identifier }}: {{ .Annotations.description }}
             {{ end }}
          {{ end }}
         {{ if gt (len .Alerts.Resolved) 0 }}
         *Alerts Resolved:*
            {{ range .Alerts.Resolved }}- {{ .Annotations.identifier }}: {{ .Annotations.description }}
            {{ end }}
        {{ end }}
       {{ end }}
    {{ end }}
